# OLAP Pipeline for Credit Card Transaction Analysis

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```
CSV Data â†’ Kafka Producer â†’ Kafka Topics â†’ Spark Streaming â†’ HDFS â†’ Power BI
                                              â†“
                                         Airflow (Orchestration)
```

## ğŸ“ Cáº¥u trÃºc project

```
ODAP_pipeline/
â”œâ”€â”€ docker-compose.yml          # Docker services configuration
â”œâ”€â”€ hadoop.env                  # Hadoop environment variables
â”œâ”€â”€ data/                      # CSV data files
â”œâ”€â”€ spark-apps/                # Spark streaming applications
â”œâ”€â”€ spark-data/                # Spark temporary data
â”œâ”€â”€ dags/                      # Airflow DAGs
â”œâ”€â”€ logs/                      # Airflow logs
â”œâ”€â”€ plugins/                   # Airflow plugins
â””â”€â”€ README.md                  # Project documentation
```

## ğŸš€ Services vÃ  Ports

### Kafka Ecosystem
- **Kafka Brokers**: 9092, 9093, 9094
- **Schema Registry**: 8081
- **Kafka Connect**: 8083
- **Kafka UI**: 8080

### Hadoop Ecosystem
- **HDFS NameNode**: 9870 (Web UI), 9000 (RPC)

### Spark Ecosystem
- **Spark Master**: 8081 (Web UI), 7077 (RPC)

### Airflow
- **Airflow Webserver**: 8082


# How to start
## Build the airflow Dockerfile
```
docker compose build airflow-webserver
```
## Build the docker compose
```
docker compose up -d

(if you want to down)
docker compose down -v
```

## Run the producer 
```
docker compose --profile producer up kafka-producer
```

## Run the Spark program
```
docker exec spark-master spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 \
  /opt/spark-apps/simple_kafka_consumer.py
```

## Trigger the csv_merge_for_powerbi dag on Airflow UI
- Go to http://localhost:8082/dags/csv_merge_for_powerbi
- Turn it on

## Cat the merge download csv file
```
chmod +x download_csv_from_hdfs.sh
./download_csv_from_hdfs.sh
```
